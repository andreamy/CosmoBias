{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('../PyScripts/')\n",
    "\n",
    "import utils.function_library \n",
    "importlib.reload(utils.function_library)\n",
    "from utils.function_library import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A preliminary study of larger covmats: As the dimension of the data set increases, ever more covmat elements must be computed. Does this mean each element must be known to better precision to avoid biases (highly probably so)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This is an example for a KiDS1000-like survey with 6 bins instead of 5. The point would be\n",
    " to repeat the study with 5,6,7,8,9,10 bins (like Euclid) to study how the increase in \n",
    " dimension affects the bias. \n",
    "\"\"\"\n",
    "\n",
    "#Load theory vector\n",
    "fake_theory_vector = np.reshape(np.load(\"../Output/xipm/euklids_6_zbins/\"\n",
    "                             \"vector_xipm_kids_euklids_6_zbins.npy\"), (-1,1))\n",
    "#Load theory covariance matrix\n",
    "fake_covmat = np.load(\"../Output/covmats/CovMatrix_euklids_6_zbins.npy\") \n",
    "\n",
    "#Create data vector with Euklids characteristics\n",
    "fake_data_vector = np.random.multivariate_normal(mean=fake_theory_vector[:,0],\n",
    "                                                 cov=fake_covmat) \n",
    "\n",
    "# Dictionary with parameters and their fiducial values\n",
    "cosmo_params_newthetaI =  {\"Omega_m\":0.24, \"Omega_v\":0.69, \"sigma_8\":0.85,\n",
    "                           \"w0\":-1.0, \"wa\":0.0, \"n_spec\":0.90, \"omb\":0.042,\n",
    "                           \"h0\":0.68, } \n",
    "\n",
    "# Cosmolike inifile for Euklids\n",
    "euklids_inifile = '../CosmoCov/covs/ini_files/cov_euklids.ini'\n",
    "\n",
    "# 1 sigma errors(standard deviation)\n",
    "bestfit_sigmas = K1000_standard_dev_symmetrized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy right file into the .ini file that will be called by bash script\n",
    "subprocess.run(['cp', '../CosmoCov/covs/ini_files/cov_euklids_copy.ini',\n",
    "            euklids_inifile], stdout=subprocess.PIPE, universal_newlines=True)\n",
    "\n",
    "# Create X matrix\n",
    "Xmatrix = create_X_matrix(\"euklids_6_zbins\", fake_theory_vector,\n",
    "                            euklids_inifile, N_parameters = 8, euklids=True)\n",
    "\n",
    "np.save(\"../Output/Xmatrices/X_euklids_6bins.npy\", Xmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case for 5 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_euklids = np.load(\"../Output/Xmatrices/X_euklids_5bins.npy\")\n",
    "\n",
    "#compute shift in covariance matrix due to a 5% increase of each matrix element\n",
    "shift_euklids_5bins = shift_covmat_elements(\"euklids_5bins\",X_euklids, \n",
    "                                            fake_covmat, fake_theory_vector, \n",
    "                                            fake_data_vector,\n",
    "                                             cosmo_params_newthetaI, 'up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case for 6 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_euklids = np.load(\"../Output/Xmatrices/X_euklids_6bins.npy\")\n",
    "\n",
    "#compute shift in covariance matrix due to a 5% increase of each matrix element\n",
    "shift_euklids_6bins = shift_covmat_elements(\"euklids_6bins\",X_euklids, \n",
    "                                            fake_covmat, fake_theory_vector, \n",
    "                                            fake_data_vector, \n",
    "                                            cosmo_params_newthetaI, 'up')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize in units of the standard deviation\n",
    "euklids_bias_5bins = np.array([shift_euklids_5bins[:,:,i]/bestfit_sigmas[j]*100 \n",
    "                               for i,j in zip([0,2,3,6,7],\n",
    "                                              range(len(bestfit_sigmas)))])\n",
    "\n",
    "euklids_bias_6bins = np.array([shift_euklids_6bins[:,:,i]/bestfit_sigmas[j]*100 \n",
    "                               for i,j in zip([0,2,3,6,7],\n",
    "                                              range(len(bestfit_sigmas)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True) #if False, scientific notation on\n",
    "\n",
    "# Computes the bias for each cosmological parameter (it returns a scalar for easier comparison)\n",
    "parameter_bias_5bins = euklids_scalar_bias(euklids_bias_5bins)\n",
    "parameter_bias_5bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_bias_6bins =euklids_scalar_bias(euklids_bias_6bins)\n",
    "parameter_bias_6bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scalar bias for each simulation \n",
    "# ** To be completed with N_zbins=7,8,9,10 (requires a long computational time) **\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(12,2), sharex=True)\n",
    "axes = plt.gca()\n",
    "axes.yaxis.label.set_size(20)\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].plot([5], [parameter_bias_5bins[i]], '.', markersize=10)\n",
    "    ax[i].plot([6], [parameter_bias_6bins[i]], '.',  markersize=10)\n",
    "    \n",
    "    ax[i].set_xlabel(ylabel_list[i], fontsize=20) \n",
    "\n",
    "                   \n",
    "#fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "ax[0].set_ylabel(r\"$\\frac{\\theta_{lin} - \\hat{\\theta}_lin}{\\sigma_i}$\", \n",
    "                 fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(top = 0.98, bottom = 0.02, right = 1, left = 0, \n",
    "                    hspace = 0.07, wspace = 0.05)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../Output/plots/point9_scalarbias_zbins.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
